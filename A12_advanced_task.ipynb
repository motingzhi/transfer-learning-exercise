{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: keras in c:\\users\\pc\\anaconda3\\lib\\site-packages (2.4.3)\n",
      "Requirement already satisfied: scipy>=0.14 in c:\\users\\pc\\anaconda3\\lib\\site-packages (from keras) (1.4.1)\n",
      "Requirement already satisfied: h5py in c:\\users\\pc\\anaconda3\\lib\\site-packages (from keras) (2.10.0)\n",
      "Requirement already satisfied: pyyaml in c:\\users\\pc\\anaconda3\\lib\\site-packages (from keras) (5.3.1)\n",
      "Requirement already satisfied: numpy>=1.9.1 in c:\\users\\pc\\appdata\\roaming\\python\\python38\\site-packages (from keras) (1.19.4)\n",
      "Requirement already satisfied: six in c:\\users\\pc\\anaconda3\\lib\\site-packages (from h5py->keras) (1.15.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install keras\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "  # %tensorflow_version only exists in Colab.\n",
    "  %tensorflow_version 2.x\n",
    "except Exception:\n",
    "  pass\n",
    "\n",
    "# Load the TensorBoard notebook extension\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ignore  the warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('always')\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# data visualisation and manipulation\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import style\n",
    "import seaborn as sns\n",
    " \n",
    "#configure\n",
    "# sets matplotlib to inline and displays graphs below the corressponding cell.\n",
    "%matplotlib inline  \n",
    "style.use('fivethirtyeight')\n",
    "sns.set(style='whitegrid',color_codes=True)\n",
    "\n",
    "#model selection\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score,precision_score,recall_score,confusion_matrix,roc_curve,roc_auc_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "#preprocess.\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "#dl libraraies\n",
    "from keras import backend as K\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.optimizers import Adam,SGD,Adagrad,Adadelta,RMSprop\n",
    "from keras.utils import to_categorical\n",
    "from keras.callbacks import ModelCheckpoint,EarlyStopping,TensorBoard,CSVLogger,ReduceLROnPlateau,LearningRateScheduler\n",
    "\n",
    "# specifically for cnn\n",
    "from keras.layers import Dropout, Flatten,Activation\n",
    "from keras.layers import Conv2D, MaxPooling2D, BatchNormalization,GlobalAveragePooling2D\n",
    "\n",
    "import random as rn\n",
    "\n",
    "# specifically for manipulating zipped images and getting numpy arrays of pixel values of images.\n",
    "import cv2                  \n",
    "import numpy as np  \n",
    "from tqdm import tqdm\n",
    "import os                   \n",
    "from random import shuffle  \n",
    "from zipfile import ZipFile\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'A': 0,\n",
       " 'B': 1,\n",
       " 'C': 2,\n",
       " 'D': 3,\n",
       " 'E': 4,\n",
       " 'F': 5,\n",
       " 'G': 6,\n",
       " 'H': 7,\n",
       " 'I': 8,\n",
       " 'J': 9,\n",
       " 'K': 10,\n",
       " 'L': 11,\n",
       " 'M': 12,\n",
       " 'N': 13,\n",
       " 'O': 14,\n",
       " 'P': 15,\n",
       " 'Q': 16,\n",
       " 'R': 17,\n",
       " 'S': 18,\n",
       " 'T': 19,\n",
       " 'U': 20,\n",
       " 'V': 21,\n",
       " 'W': 22,\n",
       " 'X': 23,\n",
       " 'Y': 24,\n",
       " 'Z': 25}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lookup = dict()\n",
    "reverselookup = dict()\n",
    "count = 0\n",
    "for j in os.listdir('./HGM-1.0/Below_CAM'):\n",
    "    if not j.startswith('.'): # If running this code locally, this is to \n",
    "                              # ensure you aren't reading in hidden folders\n",
    "        lookup[j] = count\n",
    "        reverselookup[count] = j\n",
    "        count = count + 1\n",
    "lookup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMG_SIZE = [150,100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "name=['Below_CAM','Front_CAM','Left_CAM', 'Right_CAM']\n",
    "x_data = []\n",
    "y_data = []\n",
    "\n",
    "datacount = 0 # We'll use this to tally how many images are in our dataset\n",
    "for i in range(0, 4): # Loop over the ten top-level folders\n",
    "    for j in os.listdir('./HGM-1.0/' + name[i] + '/'):\n",
    "#         print(j)\n",
    "        if not j.startswith('.'): # Again avoid hidden folders\n",
    "            count = 0 # To tally images of a given gesture\n",
    "            for k in os.listdir('./HGM-1.0/' + \n",
    "                                name[i] + '/' + j + '/'):\n",
    "                                # Loop over the images\n",
    "                img = Image.open('./HGM-1.0/' + \n",
    "                                 name[i] + '/' + j + '/' + k).convert('L')\n",
    "                                # Read in and convert to greyscale\n",
    "                img = img.resize((128, 72))\n",
    "                arr = np.array(img)\n",
    "                x_data.append(arr) \n",
    "                count = count + 1\n",
    "            y_values = np.full((count, 1), lookup[j]) \n",
    "            y_data.append(y_values)\n",
    "            datacount = datacount + count\n",
    "x_data = np.array(x_data, dtype = 'float32')\n",
    "y_data = np.array(y_data)\n",
    "y_data = y_data.reshape(datacount, 1) # Reshape to be the correct size\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4160\n"
     ]
    }
   ],
   "source": [
    "print(datacount)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # check some image\n",
    "# fig,ax=plt.subplots(5,2)\n",
    "# fig.set_size_inches(15,15)\n",
    "# for i in range(5):\n",
    "#     for j in range (2):\n",
    "#         l=rn.randint(0,len(y_data))\n",
    "#         ax[i,j].imshow(x_data[l])\n",
    "#         ax[i,j].set_title(reverselookup[y_data[l,0]])\n",
    "        \n",
    "# plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_data=to_categorical(y_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4160, 72, 128, 1)\n",
      "(4160, 26)\n"
     ]
    }
   ],
   "source": [
    "# y_data=to_categorical(y_data)\n",
    "x_data = x_data.reshape((datacount, 72, 128,1))\n",
    "x_data = x_data/255\n",
    "print(x_data.shape)\n",
    "print(y_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train,x_further,y_train,y_further = train_test_split(x_data,y_data,test_size = 0.2)\n",
    "x_validate,x_test,y_validate,y_test = train_test_split(x_further,y_further,test_size = 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import layers\n",
    "from keras import models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=models.Sequential()\n",
    "model.add(layers.Conv2D(32, (5, 5), strides=(2, 2), activation='relu', input_shape=(72, 128,1))) \n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu')) \n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(128, activation='relu'))\n",
    "model.add(layers.Dense(26, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "52/52 [==============================] - 12s 191ms/step - loss: 3.2665 - accuracy: 0.0374 - val_loss: 3.2606 - val_accuracy: 0.0264\n",
      "Epoch 2/10\n",
      "52/52 [==============================] - 6s 120ms/step - loss: 3.2562 - accuracy: 0.0502 - val_loss: 3.2746 - val_accuracy: 0.0529\n",
      "Epoch 3/10\n",
      "52/52 [==============================] - 6s 119ms/step - loss: 3.2306 - accuracy: 0.0643 - val_loss: 3.2693 - val_accuracy: 0.0601\n",
      "Epoch 4/10\n",
      "52/52 [==============================] - 6s 112ms/step - loss: 3.1791 - accuracy: 0.0760 - val_loss: 3.2204 - val_accuracy: 0.0817\n",
      "Epoch 5/10\n",
      "52/52 [==============================] - 6s 117ms/step - loss: 3.1114 - accuracy: 0.1011 - val_loss: 3.2141 - val_accuracy: 0.0817\n",
      "Epoch 6/10\n",
      "52/52 [==============================] - 5s 104ms/step - loss: 2.9640 - accuracy: 0.1339 - val_loss: 3.1622 - val_accuracy: 0.0913\n",
      "Epoch 7/10\n",
      "52/52 [==============================] - 6s 110ms/step - loss: 2.8124 - accuracy: 0.1693 - val_loss: 3.1032 - val_accuracy: 0.1106\n",
      "Epoch 8/10\n",
      "52/52 [==============================] - 6s 120ms/step - loss: 2.6851 - accuracy: 0.2087 - val_loss: 3.0868 - val_accuracy: 0.0962\n",
      "Epoch 9/10\n",
      "52/52 [==============================] - 10s 185ms/step - loss: 2.5388 - accuracy: 0.2640 - val_loss: 3.0922 - val_accuracy: 0.1226\n",
      "Epoch 10/10\n",
      "52/52 [==============================] - 8s 160ms/step - loss: 2.3488 - accuracy: 0.3132 - val_loss: 3.1386 - val_accuracy: 0.1298\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x26324161e20>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer='rmsprop',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "log_dir=\"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "model.fit(x_train, y_train, epochs=10, batch_size=64, verbose=1, validation_data=(x_validate, y_validate),callbacks=[tensorboard_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ERROR: Could not find `tensorboard`. Please ensure that your PATH\n",
       "contains an executable `tensorboard` program, or explicitly specify\n",
       "the path to a TensorBoard binary by setting the `TENSORBOARD_BINARY`\n",
       "environment variable."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir logs/fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 1s 22ms/step - loss: 3.0791 - accuracy: 0.1442\n",
      "Accuracy:0.14423076808452606\n"
     ]
    }
   ],
   "source": [
    "[loss, acc] = model.evaluate(x_test,y_test,verbose=1)\n",
    "print(\"Accuracy:\" + str(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########Pre-trained model on 20 hand gestures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data = []\n",
    "y_data  = []\n",
    "datacount = 0 # We'll use this to tally how many images are in our dataset\n",
    "itemcount= 0\n",
    "\n",
    "for i in range(0, 4): # Loop over the ten top-level folders\n",
    "    for j in os.listdir('./HGM-1.0/' + name[i] + '/'):\n",
    "        itemcount+=1\n",
    "        if not j.startswith('.'): # Again avoid hidden folders\n",
    "            count = 0 # To tally images of a given gesture\n",
    "            for k in os.listdir('./HGM-1.0/' + \n",
    "                                name[i] + '/' + j + '/'):\n",
    "                                # Loop over the images\n",
    "                img = Image.open('./HGM-1.0/' + \n",
    "                                 name[i] + '/' + j + '/' + k).convert('L')\n",
    "                                # Read in and convert to greyscale\n",
    "                img = img.resize((128, 72))\n",
    "                arr = np.array(img)\n",
    "                x_data.append(arr) \n",
    "                count = count + 1\n",
    "            y_values = np.full((count, 1), lookup[j]) \n",
    "            y_data.append(y_values)\n",
    "            datacount = datacount + count\n",
    "        if itemcount>19:\n",
    "            break\n",
    "x_data = np.array(x_data, dtype = 'float32')\n",
    "y_data = np.array(y_data)\n",
    "y_data = y_data.reshape(datacount, 1) # Reshape to be the correct size\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_data=to_categorical(y_data)\n",
    "x_data = x_data.reshape((datacount, 72, 128,1))\n",
    "x_data = x_data/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_further,y_train,y_further = train_test_split(x_data,y_data,test_size = 0.2)\n",
    "x_validate,x_test,y_validate,y_test = train_test_split(x_further,y_further,test_size = 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=models.Sequential()\n",
    "model.add(layers.Conv2D(32, (5, 5), strides=(2, 2), activation='relu', input_shape=(72, 128,1))) \n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu')) \n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(128, activation='relu'))\n",
    "model.add(layers.Dense(20, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "12/12 [==============================] - 6s 433ms/step - loss: 2.9754 - accuracy: 0.1375 - val_loss: 2.9366 - val_accuracy: 0.2065\n",
      "Epoch 2/10\n",
      "12/12 [==============================] - 2s 129ms/step - loss: 2.9068 - accuracy: 0.1698 - val_loss: 2.7688 - val_accuracy: 0.2065\n",
      "Epoch 3/10\n",
      "12/12 [==============================] - 2s 129ms/step - loss: 2.7951 - accuracy: 0.1753 - val_loss: 2.7364 - val_accuracy: 0.2065\n",
      "Epoch 4/10\n",
      "12/12 [==============================] - 1s 125ms/step - loss: 2.7400 - accuracy: 0.1796 - val_loss: 2.6610 - val_accuracy: 0.2065\n",
      "Epoch 5/10\n",
      "12/12 [==============================] - 1s 122ms/step - loss: 2.6228 - accuracy: 0.1874 - val_loss: 2.7289 - val_accuracy: 0.1630\n",
      "Epoch 6/10\n",
      "12/12 [==============================] - 2s 143ms/step - loss: 2.6626 - accuracy: 0.1697 - val_loss: 2.6551 - val_accuracy: 0.1957\n",
      "Epoch 7/10\n",
      "12/12 [==============================] - 2s 134ms/step - loss: 2.6550 - accuracy: 0.1781 - val_loss: 2.5808 - val_accuracy: 0.2174\n",
      "Epoch 8/10\n",
      "12/12 [==============================] - 2s 130ms/step - loss: 2.5363 - accuracy: 0.1880 - val_loss: 2.5843 - val_accuracy: 0.1957\n",
      "Epoch 9/10\n",
      "12/12 [==============================] - 1s 120ms/step - loss: 2.4961 - accuracy: 0.2102 - val_loss: 2.5879 - val_accuracy: 0.2391\n",
      "Epoch 10/10\n",
      "12/12 [==============================] - 1s 124ms/step - loss: 2.4306 - accuracy: 0.2328 - val_loss: 2.5516 - val_accuracy: 0.2283\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x26330145040>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer='rmsprop',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "log_dir=\"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "model.fit(x_train, y_train, epochs=10, batch_size=64, verbose=1, validation_data=(x_validate, y_validate),callbacks=[tensorboard_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ERROR: Could not find `tensorboard`. Please ensure that your PATH\n",
       "contains an executable `tensorboard` program, or explicitly specify\n",
       "the path to a TensorBoard binary by setting the `TENSORBOARD_BINARY`\n",
       "environment variable."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir logs/fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 6ms/step - loss: 2.7459 - accuracy: 0.1304\n",
      "Accuracy:0.1304347813129425\n"
     ]
    }
   ],
   "source": [
    "[loss, acc] = model.evaluate(x_test,y_test,verbose=1)\n",
    "print(\"Accuracy:\" + str(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('gesture_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "basic_model = load_model(\"gesture_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(5):\n",
    "    basic_model.layers[i].trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Freeze the first 3 layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(3):\n",
    "    basic_model.layers[i].trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(3,5):\n",
    "    basic_model.layers[i].trainable = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add three more layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "ll = basic_model.layers[4].output\n",
    "ll = Dense(32)(ll)\n",
    "ll = Dense(64)(ll)\n",
    "ll = Dense(26,activation=\"softmax\")(ll)\n",
    "\n",
    "new_model =keras.Model(inputs=basic_model.input,outputs=ll)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "You are trying to load a weight file containing 5 layers into a model with 16 layers.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-68-a2db74640ef3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m base1_model = keras.applications.VGG19(\n\u001b[0m\u001b[0;32m      2\u001b[0m     \u001b[0mweights\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"./gesture_model.h5\"\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[1;31m# Load weights pre-trained on ImageNet.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0minput_shape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m72\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m128\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0minclude_top\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m )  # Do not include the classifier at the top.\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\applications\\vgg19.py\u001b[0m in \u001b[0;36mVGG19\u001b[1;34m(include_top, weights, input_tensor, input_shape, pooling, classes, classifier_activation)\u001b[0m\n\u001b[0;32m    226\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweights_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    227\u001b[0m   \u001b[1;32melif\u001b[0m \u001b[0mweights\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 228\u001b[1;33m     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    229\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    230\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mload_weights\u001b[1;34m(self, filepath, by_name, skip_mismatch, options)\u001b[0m\n\u001b[0;32m   2209\u001b[0m             f, self.layers, skip_mismatch=skip_mismatch)\n\u001b[0;32m   2210\u001b[0m       \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2211\u001b[1;33m         \u001b[0mhdf5_format\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_weights_from_hdf5_group\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2212\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2213\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_updated_config\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\saving\\hdf5_format.py\u001b[0m in \u001b[0;36mload_weights_from_hdf5_group\u001b[1;34m(f, layers)\u001b[0m\n\u001b[0;32m    681\u001b[0m   \u001b[0mlayer_names\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfiltered_layer_names\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    682\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlayer_names\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered_layers\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 683\u001b[1;33m     raise ValueError('You are trying to load a weight file '\n\u001b[0m\u001b[0;32m    684\u001b[0m                      \u001b[1;34m'containing '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlayer_names\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    685\u001b[0m                      \u001b[1;34m' layers into a model with '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered_layers\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: You are trying to load a weight file containing 5 layers into a model with 16 layers."
     ]
    }
   ],
   "source": [
    "model.fit(x_train, y_train, epochs=10, batch_size=64, verbose=1, validation_data=(x_validate, y_validate),callbacks=[tensorboard_callback])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Report:\n",
    "\n",
    "1.Through the comparison(refer to another notebook file using imagenet), I can see that the final recognition accuracy with the test data is improved dramatcally.\n",
    "\n",
    "2.The 2 challenges you find and overcome during this assignment: \n",
    "One is understanding of transfer learning. I spend a lot of time to learn about the concept of transfer learning;\n",
    "Another one is how to deal with data shape. You can see from the notebook I didn't cope with this well."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
